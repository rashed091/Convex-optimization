{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><mathjax>$ \\def\\prox{\\text{prox}} $</mathjax>\n",
    "  In a <a href=\"/blog/subgradient-descent.html#usage\">previous post</a>, I mentioned that one cannot\n",
    "hope to asymptotically outperform the <mathjax>$O(\\frac{1}{\\epsilon^2})$</mathjax> convergence\n",
    "rate of Subgradient Descent when dealing with a non-differentiable objective\n",
    "function. This is in fact only half-true; Subgradient Descent cannot be beat\n",
    "<em>using only first-order information</em> (that is, gradients and subgradients).\n",
    "In this article, I'll describe Proximal Gradient Descent, an algorithm that\n",
    "exploits problem structure to obtain a rate of <mathjax>$O(\\frac{1}{\\epsilon})$</mathjax>. In\n",
    "particular, Proximal Gradient is useful if the following 2 assumptions hold.\n",
    "First, the objective function must be of the form,</p>\n",
    "<p><mathjax>$$\n",
    "  \\min_{x} \\, g(x) + h(x)\n",
    "$$</mathjax></p>\n",
    "<p>with <mathjax>$g$</mathjax> is differentiable. Second <mathjax>$h$</mathjax> must be \"simple\" enough such that we\n",
    "can calculate its <mathjax>$\\prox$</mathjax> operator very quickly,</p>\n",
    "<p><mathjax>$$\n",
    "  \\prox_{h}(x) = \\min_{u} h(u) + \\frac{1}{2} ||u-x||_2^2\n",
    "$$</mathjax></p>\n",
    "<p>Using these two assumptions, we can obtain a convergence rate identical to\n",
    "Gradient Descent even when optimizing non-differentiable objective functions.</p>\n",
    "<h1><a name=\"implementation\" href=\"#implementation\">How does it work?</a></h1>\n",
    "<div class=\"pseudocode\">\n",
    "<p><strong>Input</strong>: initial iterate <mathjax>$x^{(0)}$</mathjax></p>\n",
    "<ol>\n",
    "<li>For <mathjax>$t = 0, 1, 2, \\ldots$</mathjax><ol>\n",
    "<li>Let <mathjax>$x^{(t+1)} = \\prox_{ \\alpha^{(t)} h } \\left( x^{(t)} - \\alpha^{(t)} \\nabla g(x^{(t)}) \\right)$</mathjax></li>\n",
    "<li>if converged, return <mathjax>$x^{(t+1)}$</mathjax></li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n",
    "<p><a id=\"intuition\"></a></p>\n",
    "<h1><a name=\"intuition\" href=\"#intuition\">Intuition for the <mathjax>$\\prox$</mathjax> Operator</a></h1>\n",
    "<p>At first sight, the <mathjax>$\\prox$</mathjax> operator looks suspicious.  Where did it come\n",
    "from? Why did someone really think it would work?  It ends up that we can\n",
    "derive the update for Gradient Descent and the update for Gradient Descent\n",
    "almost identically. First, notice that the Gradient Descent Update is the\n",
    "solution to the following quadratic approximation to <mathjax>$f(x)$</mathjax>.</p>\n",
    "<mathjax>$$\n",
    "\\begin{align*}\n",
    "x^{(t+1)} &= \\arg\\min_{y} f(x^{(t)}) + \\nabla f(x^{(t)})^T (y-x^{(t)}) + \\frac{L}{2} ||y-x^{(t)}||_2^2 \\\\\n",
    "  0      &= \\nabla f(x^{(t)}) + L (x^{(t+1)}-x^{(t)}) \\\\\n",
    "  x^{(t+1)}  &= x^{(t)} - \\frac{1}{L} \\nabla f(x^{(t)})\\\\\n",
    "\\end{align*}$$</mathjax>\n",
    "<p>We take the gradient of the right hand side with respect to <mathjax>$y$</mathjax> and set it to\n",
    "zero in the second line.  Now replace <mathjax>$f$</mathjax> with <mathjax>$g$</mathjax>, and add <mathjax>$h(y)$</mathjax> to the\n",
    "very end of the first line,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  x^{(t+1)}\n",
    "  & = \\arg\\min_{y} g(x^{(t)}) + \\nabla g(x^{(t)})^T (y-x^{(t)}) + \\frac{L}{2} ||y-x^{(t)}||_2^2 + h(y) \\\\\n",
    "  & = \\arg\\min_{y} g(x^{(t)}) + \\frac{L}{2} \\left( \\frac{2}{L} \\nabla g(x^{(t)})^T (y-x^{(t)}) \\right) + \\frac{L}{2} ||y-x^{(t)}||_2^2 + h(y) + \\frac{L}{2} ||\\nabla g(x^{(t)})||_2^2 \\\\\n",
    "  & = \\arg\\min_{y} \\frac{L}{2} || y - (x^{(t)} - \\frac{1}{L} \\nabla g(x^{(t)})) ||_2^2 + h(y) \\\\\n",
    "  & = \\prox_{ \\frac{1}{L} h }(x^{(t)} - \\frac{1}{L} \\nabla g(x^{(t)})) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>This time, we add constants (with respect to <mathjax>$y$</mathjax>) such that we can pull the\n",
    "<mathjax>$\\nabla g(x^{(t)})^T (y-x^{(t)})$</mathjax> into the quadratic term, leading us to the\n",
    "Proximal Gradient Descent update.</p>\n",
    "<h1><a name=\"example\" href=\"#example\">A Small Example</a></h1>\n",
    "<p>Let's now see how well Proximal Gradient Descent works.  For this example,\n",
    "we'll solve the following problem,</p>\n",
    "<p><mathjax>$$\n",
    "  \\min_{x} \\, \\log(1 + \\exp(-2x)) + ||x||_1\n",
    "$$</mathjax></p>\n",
    "<p>Letting <mathjax>$g(x) = \\log(1+\\exp(-2x))$</mathjax> and <mathjax>$h(x) = ||x||_1$</mathjax>, it can be shown\n",
    "that,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  \\nabla g(x) &= \\frac{1}{1 + \\exp(-2x)} \\left( \\exp(-2x) \\right) (-2) \\\\\n",
    "  \\prox_{\\alpha h}(x) &= \\text{sign}(x) \\max(0, \\text{abs}(x) - \\alpha) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>We'll use a variant of <a href=\"#line_search\">Backtracking Line Search</a> modified for\n",
    "Proximal Gradient Descent and an initial choice of <mathjax>$x^{(0)} = 5$</mathjax>.</p>\n",
    "\n",
    "<div class=\"img-center\">\n",
    "  <img src=\"../images/convergence2.png\"/>\n",
    "  <span class=\"caption\">\n",
    "    This plot shows how quickly the objective function decreases as the\n",
    "    number of iterations increases.\n",
    "  </span>\n",
    "</div>\n",
    "\n",
    "<div class=\"img-center\">\n",
    "  <img src=\"../images/iterates2.png\"/>\n",
    "  <span class=\"caption\">\n",
    "    This plot shows the actual iterates and the objective function evaluated at\n",
    "    those points. More red indicates a higher iteration number.\n",
    "  </span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a name=\"proof\" href=\"#proof\">Why does it work?</a></h1>\n",
    "<p>Proximal Gradient Descent, like regular Gradient Descent, is a \"descent\"\n",
    "method where the objective value is guaranteed to decrease. In fact, the\n",
    "assumptions for Proximal Gradient Descent's <mathjax>$g(x)$</mathjax> are the identical to the\n",
    "Gradient Descent assumptions for <mathjax>$f(x)$</mathjax>. The only additional condition is\n",
    "that <mathjax>$h(x)$</mathjax> be convex,</p>\n",
    "<ol>\n",
    "<li><mathjax>$g(x)$</mathjax> is convex, differentiable, and finite for all <mathjax>$x$</mathjax></li>\n",
    "<li>a finite solution <mathjax>$x^{*}$</mathjax> exists</li>\n",
    "<li><mathjax>$\\nabla g(x)$</mathjax> is Lipschitz continuous with constant <mathjax>$L$</mathjax>. That is, there must\n",
    "   be an <mathjax>$L$</mathjax> such that,</li>\n",
    "</ol>\n",
    "<p><mathjax>$$\n",
    "  || \\nabla g(x) - \\nabla g(y) ||_2 \\le L || x - y ||_2 \\qquad \\forall x,y\n",
    "$$</mathjax></p>\n",
    "<ol>\n",
    "<li><mathjax>$h(x)$</mathjax> is convex</li>\n",
    "</ol>\n",
    "<p><strong>Proof Outline</strong> The majority of the convergence proof for Proximal Gradient\n",
    "Descent is identical to the proof for regular Gradient Descent. The key is to\n",
    "carefully choose a function <mathjax>$G_{\\alpha}(x)$</mathjax> that can take the place of <mathjax>$\\nabla\n",
    "f(x)$</mathjax>.  Once it is defined, we can rephrase Proximal Gradient Descent as\n",
    "<mathjax>$x^{(t+1)} = x^{(t)} - \\alpha^{(t)} G_{\\alpha^{(t)}}(x^{(t)})$</mathjax>. Next, we'll\n",
    "show that,</p>\n",
    "<p><mathjax>$$\n",
    "  (g+h)(x^{(t+1)}) \\le (g+h)(x^{*}) + G_{\\alpha^{(t)}}(x^{(t)})^T (x-x^{*}) - \\frac{\\alpha^{(t)}}{2} ||G_{\\alpha^{(t)}}(x^{(t)})||_2^2\n",
    "$$</mathjax></p>\n",
    "<p>Once we have this, we can repeat the Gradient Descent proof verbatim with <mathjax>$g\n",
    "+ h \\rightarrow f$</mathjax> and <mathjax>$G_{\\alpha^{(t)}}(x^{(t)}) \\rightarrow \\nabla\n",
    "  f(x^{(t)})$</mathjax>.</p>\n",
    "<p><strong>Step 1</strong> Phrase Proximal Gradient Descent as <mathjax>$x^{(t+1)} = x^{(t)} - \\alpha^{(t)} G_{\\alpha^{(t)}}(x^{(t)})$</mathjax>. Define <mathjax>$G$</mathjax>\n",
    "as follows,</p>\n",
    "<p><mathjax>$$\n",
    "  G_{\\alpha}(x) \\triangleq \\frac{1}{\\alpha} (x - \\prox_{\\alpha h}( x - \\alpha \\nabla g(x)))\n",
    "$$</mathjax></p>\n",
    "<p>Now let <mathjax>$x^{+} \\triangleq x^{(t+1)}$</mathjax>, <mathjax>$x \\triangleq x^{(t)}$</mathjax>, and <mathjax>$\\alpha\n",
    "\\triangleq \\alpha^{(t)}$</mathjax>. Using <mathjax>$G$</mathjax>, we can reframe Proximal Gradient Descent\n",
    "as a typical descent method,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  x^{+}\n",
    "  &= x - \\alpha G_{\\alpha}(x) \\\\\n",
    "  &= x - \\alpha \\left(\n",
    "      \\frac{1}{\\alpha} (x - \\prox_{\\alpha h}( x - \\alpha \\nabla g(x))\n",
    "    \\right) \\\\\n",
    "  &= x - (x - \\prox_{\\alpha h}( x - \\alpha \\nabla g(x)) \\\\\n",
    "  &= \\prox_{\\alpha h}( x - \\alpha \\nabla g(x)) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p><strong>Step 2</strong> Show that <mathjax>$G_{\\alpha}(x)$</mathjax> can be used like Gradient\n",
    "Descent's <mathjax>$\\nabla f(x)$</mathjax>. Our goals is to obtain a statement identical to\n",
    "<mathjax>$f(x^{+}) \\le f(x^{*}) + \\nabla f(x)^T (x-x^{*}) - \\frac{\\alpha}{2} ||\\nabla\n",
    "f(x)||_2^2$</mathjax> except with <mathjax>$G_{\\alpha}(x)$</mathjax> instead of <mathjax>$\\nabla f(x)$</mathjax>.  Once we\n",
    "have this, the rest of the proof is exactly the same as Gradient Descent's.\n",
    "Begin by recalling the Lipschitz condition on <mathjax>$g$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "  g(y) \\le g(x) + \\nabla g(x)^T (y-x) + \\frac{L}{2} ||y-x||_2^2\n",
    "$$</mathjax></p>\n",
    "<p>Substitute <mathjax>$y = x^{+} = x - \\alpha G_{\\alpha}(x)$</mathjax> to obtain,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  g(x - \\alpha G_{\\alpha}(x))\n",
    "  & \\le g(x) + \\nabla g(x)^T(x - \\alpha G_{\\alpha}(x) - x) + \\frac{L}{2}||x - \\alpha G_{\\alpha}(x) - x||_2^2 \\\\\n",
    "  &= g(x) - \\alpha \\nabla g(x)^T G_{\\alpha}(x) + \\frac{L ( \\alpha )^2}{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Assume then that <mathjax>$\\alpha \\le \\frac{1}{L}$</mathjax> (this is what Backtracking Line\n",
    "Search does), We can upper bound <mathjax>$\\frac{L ( \\alpha )^2}{2} \\le\n",
    "\\frac{\\alpha}{2}$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  g(x - \\alpha G_{\\alpha}(x))\n",
    "  & \\le g(x) - \\alpha \\nabla g(x)^T G_{\\alpha}(x) + \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Then add <mathjax>$h(x - \\alpha G_{\\alpha}(x))$</mathjax> to both sides,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  (g+h)(x - \\alpha G_{\\alpha}(x))\n",
    "  & \\le g(x) - \\alpha \\nabla g(x)^T G_{\\alpha}(x) + \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "  & \\quad + h(x - \\alpha G_{\\alpha}(x)) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Next, we'll upper bound <mathjax>$g(x)$</mathjax> and <mathjax>$h(x - \\alpha G_{\\alpha}(x))$</mathjax> using the definition of convexity. The following 2 equations hold for all <mathjax>$z$</mathjax>, For <mathjax>$g$</mathjax>, we'll use,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  g(z) & \\ge g(x) + \\nabla g(x)^T (z-x) \\\\\n",
    "  g(z) + \\nabla g(x)^T (x-z) & \\ge g(x) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>For <mathjax>$h$</mathjax> we have something a bit more mysterious,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  h(z)\n",
    "  & \\ge h(x - \\alpha G_{\\alpha}(x)) + [G_{\\alpha}(x) - \\nabla g(x)]^T (z-(x - \\alpha G_{\\alpha}(x))) \\\\\n",
    "  h(z) + [G_{\\alpha}(x) - \\nabla g(x)]^T(x - \\alpha G_{\\alpha}(x) - z)\n",
    "  & \\ge h(x - \\alpha G_{\\alpha}(x))\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Where did that come from? It so happens that <mathjax>$G_{\\alpha}(x) - \\nabla\n",
    "g(x)$</mathjax> is a valid subgradient for <mathjax>$h$</mathjax> at <mathjax>$x - \\alpha G_{\\alpha}(x)$</mathjax>.\n",
    "Recall the 2 definitions we have for <mathjax>$x^{+}$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  x^{+}\n",
    "  &= \\prox_{\\alpha h} (x - \\alpha \\nabla g(x)) \\\\\n",
    "  &= \\arg\\min_{u} \\alpha h(u) + \\frac{1}{2} ||u - (x - \\alpha \\nabla g(x))||_2^2 \\\\\n",
    "  0\n",
    "  & \\in \\alpha \\partial h(x^{+}) + x^{+} - (x - \\alpha \\nabla g(x)) \\\\\n",
    "  (x - \\alpha \\nabla g(x)) - x^{+}\n",
    "  & \\in \\alpha \\partial h(x^{+}) \\\\\n",
    "  (x - \\alpha \\nabla g(x)) - (x - \\alpha G_{\\alpha}(x))\n",
    "  & \\in \\alpha \\partial h(x^{+}) \\\\\n",
    "  \\alpha [G_{\\alpha}(x)) - \\nabla g(x)]\n",
    "  & \\in \\alpha \\partial h(x^{+}) \\\\\n",
    "  [G_{\\alpha}(x)) - \\nabla g(x)]\n",
    "  & \\in \\partial h(x^{+}) \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Thus, <mathjax>$G_{\\alpha}(x)) - \\nabla g(x)$</mathjax> is a valid subgradient for <mathjax>$h$</mathjax> at\n",
    "<mathjax>$x^{+} \\triangleq x - \\alpha G_{\\alpha}(x)$</mathjax>, and the previous lower\n",
    "bound on <mathjax>$h(z)$</mathjax> holds.  Putting the previous two inequalities back into the\n",
    "preceding equation and canceling out, we can see that for all <mathjax>$z$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  (g+h)(x - \\alpha G_{\\alpha}(x))\n",
    "  & \\le g(x) - \\alpha \\nabla g(x)^T G_{\\alpha}(x) + \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "  & \\quad + h(x - \\alpha G_{\\alpha}(x)) \\\\\n",
    "  (g+h)(x - \\alpha G_{\\alpha}(x))\n",
    "  & \\le \\left( g(z) + \\nabla g(z)^T (x-z) \\right) - \\alpha \\nabla g(x)^T G_{\\alpha}(x) + \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "  & \\quad + \\left( h(z) + [G_{\\alpha}(x) - \\nabla g(x)]^T (x - \\alpha G_{\\alpha}(x) - z) \\right) \\\\\n",
    "  & = (g+h)(z) + G_{\\alpha}(x)^T (x-z) - \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Now let <mathjax>$z = x^{*}$</mathjax> to get,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  (g+h)(x^{+})\n",
    "  & \\le (g+h)(x^{*}) + G_{\\alpha}(x)^T (x-x^{*}) - \\frac{ \\alpha }{2}||G_{\\alpha}(x)||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Looking back at Step 1 of the <a href=\"/blog/gradient-descent.html#proof\">Gradient Descent\n",
    "Proof</a>, you can see that this equation is exactly the\n",
    "same as the one used before except that <mathjax>$G_{\\alpha}(x)$</mathjax> replaces <mathjax>$\\nabla\n",
    "f(x)$</mathjax>. Following the rest of the Gradient Descent proof, we find that of we\n",
    "want <mathjax>$(g+h)(x^{(t)}) - (g+h)(x^{*}) \\le \\epsilon$</mathjax>, we need\n",
    "<mathjax>$O(\\frac{1}{\\epsilon})$</mathjax> iterations, just like Gradient Descent.</p>\n",
    "<h1><a name=\"usage\" href=\"#usage\">When should I use it?</a></h1>\n",
    "<p>Proximal Gradient Descent requires being able to easily calculate\n",
    "<mathjax>$\\prox_{\\alpha h}(x)$</mathjax>.  The benefits of doing so are clear -- we can reach an\n",
    "<mathjax>$\\epsilon$</mathjax>-approximate solution in far fewer iterations than Subgradient\n",
    "Descent. But this is only valuable if the cost of an iteration of Proximal Gradient\n",
    "Descent is similar to that of Subgradient Descent. For some choices of <mathjax>$h(x)$</mathjax>,\n",
    "this actually holds (see <a href=\"#common_prox_functions\">Common Prox Functions</a>\n",
    "below); it is then that Proximal Gradient Descent should be used. For other\n",
    "cases where no closed-form solution exists, it is often better to stick with\n",
    "Subgradient Descent.</p>\n",
    "<h1><a name=\"extensions\" href=\"#extensions\">Extensions</a></h1>\n",
    "<p><a id=\"line_search\"></a>\n",
    "  <strong>Step Size</strong> The proof above assumes the step size <mathjax>$\\alpha^{(t)} \\le\n",
    "\\frac{1}{L}$</mathjax> (<mathjax>$L$</mathjax> is the Lipschitz constant of <mathjax>$g(x)$</mathjax>). Rather than guessing\n",
    "for such values, Backtracking Line Search can be employed with a slight\n",
    "modification. Recall that Backtracking Line Search chooses <mathjax>$\\alpha^{(t)}$</mathjax> such\n",
    "that,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  f(x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}))\n",
    "  & \\le f(x^{(t)}) - \\frac{\\alpha^{(t)}}{2}|| \\nabla f(x^{(t)})||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>If <mathjax>$\\alpha^{(t)} \\le \\frac{1}{L}$</mathjax>, this statement must hold. To see why, let's write out where the condition came from,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  f(x^{(t+1)})\n",
    "  & \\le f(x^{(t)}) + \\nabla f(^{(t)})^T (x^{(t+1)} - x^{(t)}) + \\frac{1}{2 \\alpha^{(t)}}||x^{(t+1)} - x^{(t)}||_2^2 \\\\\n",
    "  f(x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}))\n",
    "  & \\le f(x^{(t)}) + \\nabla f(^{(t)})^T (x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}) - x^{(t)}) \\\\\n",
    "  & \\quad + \\frac{1}{2 \\alpha^{(t)}}||x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}) - x^{(t)}||_2^2 \\\\\n",
    "  f(x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}))\n",
    "  & \\le f(x^{(t)}) - \\alpha^{(t)} ||\\nabla f(^{(t)}) ||_2^2 + \\frac{\\alpha^{(t)}}{2}|| \\nabla f(x^{(t)})||_2^2 \\\\\n",
    "  f(x^{(t)} - \\alpha^{(t)} \\nabla f(x^{(t)}))\n",
    "  & \\le f(x^{(t)}) - \\frac{\\alpha^{(t)}}{2}|| \\nabla f(x^{(t)})||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>If we assume that <mathjax>$f$</mathjax> is <mathjax>$L$</mathjax>-Lipschitz, then <mathjax>$\\alpha^{(t)} = \\frac{1}{L}$</mathjax> is\n",
    "precisely the Lipschitz assumption. Recall now that for this problem, we have\n",
    "<mathjax>$G_{\\alpha^{(t)}}(x^{(t)})$</mathjax> in place of <mathjax>$\\nabla f(x^{(t)})$</mathjax>. Replacing <mathjax>$f$</mathjax> with\n",
    "<mathjax>$g+h$</mathjax> and <mathjax>$\\nabla f(x)$</mathjax> with <mathjax>$G_{\\alpha}(x)$</mathjax>, we come to a similar condition,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  (g+h)(x^{(t+1)})\n",
    "  & \\le (g+h)(x^{(t)}) - \\frac{\\alpha^{(t)}}{2}|| G_{\\alpha^{(t)}}(x^{(t)}) ||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>In other words, we can perform Backtracking Line Search for Proximal Gradient Descent as follows,</p>\n",
    "<div class=\"pseudocode\">\n",
    "<p><strong>Input</strong>: iterate <mathjax>$x^{(t)}$</mathjax>, initial step size <mathjax>$\\alpha_0$</mathjax>, step factor <mathjax>$\\beta$</mathjax></p>\n",
    "<ol>\n",
    "<li><mathjax>$\\alpha = \\alpha_0$</mathjax></li>\n",
    "<li>While True<ol>\n",
    "<li>Calculate <mathjax>$G_{\\alpha}(x^{(t)}) = \\frac{1}{\\alpha}( x - \\prox_{\\alpha h}(x^{(t)} - \\alpha \\nabla g(x)) )$</mathjax></li>\n",
    "<li>if <mathjax>$(g+h)(x^{(t+1)}) \\le (g+h)(x^{(t)}) - \\frac{\\alpha}{2}|| G_{\\alpha}(x^{(t)}) ||_2^2$</mathjax>, set <mathjax>$\\alpha^{(t)} = \\alpha$</mathjax> and return</li>\n",
    "<li>otherwise set <mathjax>$\\alpha \\leftarrow \\alpha \\beta$</mathjax> and continue</li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n",
    "<h1><a name=\"common-prox\" href=\"#common-prox\">Common <mathjax>$\\prox$</mathjax> Functions</a></h1>\n",
    "<p>There are several common choices for <mathjax>$h(x)$</mathjax> that admit particularly efficient\n",
    "<mathjax>$\\prox$</mathjax> functions. If your objective function contains one of these, consider\n",
    "applying Proximal Gradient immediately -- you'll converge far faster than\n",
    "Subgradient Descent.</p>\n",
    "<table class=\"table table-bordered table-centered\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>$h(x)$</th>\n",
    "      <th>$\\prox_{\\alpha h}(x)$</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>$||x||_1$</td>\n",
    "      <td>$\\text{sign}(x) \\max(0, \\text{abs}(x) - \\alpha)$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>$\\frac{1}{2}||x||_2^2$</td>\n",
    "      <td>$\\frac{1}{1 + \\alpha} x$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>$||x||_2$</td>\n",
    "      <td>$\\left( 1 - \\frac{\\alpha}{||x||_2} \\right) x$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>$||x||_{\\infty}$</td>\n",
    "      <td>\n",
    "          $\\text{sign}(x) \\min( \\text{abs}(x), \\theta )$\n",
    "\n",
    "        where\n",
    "\n",
    "          $\\theta = \\frac{1}{\\rho} \\sum_{j : |x_j| > |x_{(\\rho)}|} (|x_j| - \\alpha)$\n",
    "\n",
    "        where $x_{(i)}$ is is the $i$-th largest element of $x$ in magnitude and\n",
    "        $\\rho$ is the smallest $i$ such that\n",
    "        $\\sum_{j : |x_j| > |x_{(i)}|} (|x_j| - |x_{(i)}|) < \\alpha$.\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>$\\frac{1}{2} x^T Q x + b^T x$</td>\n",
    "      <td>$(\\alpha Q + I)^{-1} (x - \\alpha b)$</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<h1><a name=\"references\" href=\"#references\">References</a></h1>\n",
    "<p><strong>Proof of Convergence</strong> The original proof of convergence is thanks to\n",
    "Laurent El Ghaoui's <a href=\"http://www.eecs.berkeley.edu/~elghaoui/Teaching/EE227A/lecture18.pdf\">EE227a slides</a>.</p>\n",
    "<p><strong>List of Proximal Functions</strong>The list of proximal functions is taken from\n",
    "John Duchi's article on <a href=\"http://www.cs.berkeley.edu/~jduchi/projects/DuchiSi09c.pdf\">Forward-Backward Splitting (FOBOS)</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+zzEe+2krXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05502f9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def proximal_gradient_descent(g_gradient, h_prox, x0, alpha, n_iterations=100):\n",
    "    xs = [x0]\n",
    "    for t in range(n_iterations):\n",
    "        x = xs[-1]\n",
    "        g = g_gradient(x)\n",
    "        step = alpha(x)\n",
    "        x_plus = h_prox(x - step * g, step)\n",
    "        xs.append(x_plus)\n",
    "    return xs\n",
    "\n",
    "\n",
    "def backtracking_line_search(g, h, g_gradient, h_prox):\n",
    "    alpha_0 = 1.0\n",
    "    beta = 0.9\n",
    "\n",
    "    def search(x):\n",
    "        alpha = alpha_0\n",
    "        while True:\n",
    "            x_plus = h_prox(x - alpha * g_gradient(x), alpha)\n",
    "            G = (1.0 / alpha) * (x - x_plus)\n",
    "            if g(x_plus) + h(x_plus) <= g(x) + h(x) - 0.5 * alpha * (G * G):\n",
    "                return alpha\n",
    "            else:\n",
    "                alpha = alpha * beta\n",
    "\n",
    "    return search\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # problem definition\n",
    "    g = lambda x: np.log(1 + np.exp(-2 * x))\n",
    "    h = lambda x: abs(x)\n",
    "    function = lambda x: g(x) + h(x)\n",
    "    g_gradient = lambda x: -2 * np.exp(-x) / (1 + np.exp(-x))\n",
    "    h_prox = lambda x, alpha: np.sign(x) * max(0, abs(x) - alpha)\n",
    "    alpha = backtracking_line_search(g, h, g_gradient, h_prox)\n",
    "    x0 = 5.0\n",
    "    n_iterations = 100\n",
    "\n",
    "    # run gradient descent\n",
    "    iterates = proximal_gradient_descent(\n",
    "        g_gradient, h_prox, x0, alpha, n_iterations=n_iterations)\n",
    "    \n",
    "    evals = [function(x) for x in iterates]\n",
    "    \n",
    "    plt.plot(range(len(iterates)), evals, '--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
