{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Not far from <a href=\"http://stronglyconvex.com/blog/gradient-descent.html\">Gradient Descent</a> is another first-order\n",
    "descent algorithm (that is, an algorithm that only relies on the first\n",
    "derivative) is Subgradient Descent. In implementation, they are in fact\n",
    "identical. The only difference is on the assumptions placed on the objective\n",
    "function we wish to minimize, <mathjax>$f(x)$</mathjax>.  If you were to follow the Subgradient\n",
    "Descent algorithm to walk down a mountain, it would look something like this,</p>\n",
    "<div class=\"pseudocode\">\n",
    "<ol>\n",
    "<li>Look around you and see which way points the most downwards. If there are multiple directions that are equally downwards, just pick one.</li>\n",
    "<li>Take a step in that direction. Then repeat.</li>\n",
    "</ol>\n",
    "</div>\n",
    "<h1><a name=\"implementation\" href=\"#implementation\">How does it work?</a></h1>\n",
    "<p>As before, we adopt the usual problem definition,</p>\n",
    "<p><mathjax>$$\n",
    "  \\min_{x} \\, f(x)\n",
    "$$</mathjax></p>\n",
    "<p>But this time, we don't assume <mathjax>$f$</mathjax> is differentiable. Instead, we assume <mathjax>$f$</mathjax>\n",
    "is convex, implying that for all <mathjax>$x$</mathjax> there exists a <mathjax>$g_{x}$</mathjax> such that,</p>\n",
    "<p><mathjax>$$\n",
    "  f(y) \\ge f(x) + g_{x}^T (y - x)\n",
    "$$</mathjax></p>\n",
    "<p>If <mathjax>$f$</mathjax> is differentiable at <mathjax>$x$</mathjax> and is convex, then <mathjax>$\\nabla f(x)$</mathjax> is the only\n",
    "value for <mathjax>$g_{x}$</mathjax> that satisfies this property, but if <mathjax>$f$</mathjax> is convex but\n",
    "non-differentiable at <mathjax>$x$</mathjax>, there will be other options.</p>\n",
    "<p>The set of all <mathjax>$g_x$</mathjax> that satisfies this property called the\n",
    "<strong>subdifferential</strong> of <mathjax>$f$</mathjax> at <mathjax>$x$</mathjax> and is denoted <mathjax>$\\partial f(x)$</mathjax>. Given that we\n",
    "have an algorithm for finding a point in the subdifferential, Subgradient\n",
    "Descent is</p>\n",
    "<figure>\n",
    "  <img src=\"../images/subgradient.png\"/>\n",
    "  <figcaption>\n",
    "    $f$ is differentiable at $x_1$, so there's only one possible subgradient\n",
    "    (the actual gradient). At $x_2$, $f$ isn't differentiable, so $g_2$ and\n",
    "    $g_3$ are both in $\\partial f(x_2)$. Image taken from [EE392o slides][subgradient].\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "<div class=\"pseudocode\">\n",
    "<p><strong>Input</strong>: initial iterate <mathjax>$x^{(0)}$</mathjax></p>\n",
    "<ol>\n",
    "<li>For <mathjax>$t = 0, 1, \\ldots$</mathjax><ol>\n",
    "<li>if converged, return <mathjax>$x^{(t)}$</mathjax></li>\n",
    "<li>Compute a <a href=\"http://www.stanford.edu/class/ee392o/subgrad.pdf\">subgradient</a> of <mathjax>$f$</mathjax> at <mathjax>$x^{(t)}$</mathjax>, <mathjax>$g^{(t)} \\in \\partial f(x^{(t)})$</mathjax></li>\n",
    "<li><mathjax>$x^{(t+1)} = x^{(t)} - \\alpha^{(t)} g^{(t)}$</mathjax></li>\n",
    "</ol>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n",
    "<p>The initial iterate <mathjax>$x^{(0)}$</mathjax> can be selected arbitrarily, but <mathjax>$\\alpha^{(t)}$</mathjax>\n",
    "must be selected more carefully than in Gradient Descent. A common choice is\n",
    "<mathjax>$\\frac{1}{t}$</mathjax>.</p>\n",
    "<p><a id=\"example\"></a></p>\n",
    "<h1><a name=\"example\" href=\"#example\">A Small Example</a></h1>\n",
    "<p>Let's watch Subgradient Descent do its thing. We'll use <mathjax>$f(x) = |x|$</mathjax> as our\n",
    "objective function, giving us <mathjax>$sign(x)$</mathjax> as a valid way to compute subgradients.\n",
    "We'll use the <a href=\"#polyak\">Polyak Step Size</a> and initialize with <mathjax>$x^{(0)} = 0.75$</mathjax>.</p>\n",
    "\n",
    "<div class=\"img-center\">\n",
    "  <img src=\"../images/convergence1.png\"/>\n",
    "  <span class=\"caption\">\n",
    "    This plot shows how the objective value changes as the number of iterations\n",
    "    increase. We can see that, unlike Gradient Descent, it isn't strictly\n",
    "    decreasing. This is expected!\n",
    "  </span>\n",
    "</div>\n",
    "\n",
    "<div class=\"img-center\">\n",
    "  <img src=\"../images/iterates1.png\"/>\n",
    "  <span class=\"caption\">\n",
    "    This plot shows the actual iterates and the objective function evaluated at\n",
    "    those points. More red indicates a higher iteration number.\n",
    "  </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><a name=\"proof\" href=\"#proof\">Why does it work?</a></h1>\n",
    "<p>Now let's prove that Subgradient Descent can find <mathjax>$x^{*} = \\arg\\min_x f(x)$</mathjax>.\n",
    "We begin by making the following assumptions,</p>\n",
    "<ol>\n",
    "<li><mathjax>$f$</mathjax> is convex and finite for all <mathjax>$x$</mathjax></li>\n",
    "<li>a finite solution <mathjax>$x^{*}$</mathjax> exists</li>\n",
    "<li><mathjax>$f$</mathjax> is Lipschitz with constant <mathjax>$G$</mathjax>. That is,</li>\n",
    "</ol>\n",
    "<p><mathjax>$$\n",
    "  || f(x) - f(y) ||_2 \\le G || x - y ||_2 \\qquad \\forall x,y\n",
    "$$</mathjax></p>\n",
    "<ol>\n",
    "<li>The initial distance to <mathjax>$x^{*}$</mathjax> is bounded by <mathjax>$R$</mathjax></li>\n",
    "</ol>\n",
    "<p><mathjax>$$\n",
    "  || x^{(0)} - x^{*} || \\le R\n",
    "$$</mathjax></p>\n",
    "<p><strong>Assumptions</strong> Looking back at the convergence proof of Gradient Descent, we\n",
    "see that the main difference is in assumption 3. Before, we assumed that the\n",
    "<mathjax>$\\nabla f$</mathjax> was Lipschitz, but now we assume that <mathjax>$f$</mathjax> is Lipschitz. The\n",
    "reason for this is because non-smooth functions cannot have a Lipschitz\n",
    "Subgradient function (Imagine 2 different subgradients for <mathjax>$f$</mathjax>, <mathjax>$g_x$</mathjax> and\n",
    "<mathjax>$g_y$</mathjax>, such that <mathjax>$g_x \\ne g_y$</mathjax> and <mathjax>$x = y$</mathjax>. Then <mathjax>$||x-y||_2 = 0$</mathjax> but <mathjax>$||g_x -\n",
    "g_y||_2 \\gt 0$</mathjax>).  However, this assumption does guarantee one thing: that <mathjax>$g_x\n",
    "\\le G$</mathjax> for all <mathjax>$x$</mathjax>.</p>\n",
    "<p>Assumption 4 isn't really a condition at all.  It's just a notational\n",
    "convenience for later.</p>\n",
    "<p><strong>Proof Outline</strong> The proof for Gradient Descent relied on <mathjax>$f(x^{(t)}) -\n",
    "f(x^{*})$</mathjax> decreasing with each iteration, but the proof for Subgradient Descent\n",
    "relies on decreasing the (upper bound on) Euclidean distance between <mathjax>$x^{(t)}$</mathjax>\n",
    "and the set of all possible <mathjax>$x^{*}$</mathjax>.</p>\n",
    "<p>We begin by upper bounding the current distance to the optimal point by the\n",
    "previous distance (<mathjax>$||x^{(t)} - x^{*}||_2$</mathjax>), the previous error (<mathjax>$f(x^{(t)}) -\n",
    "f(x^{*})$</mathjax>), and the norm of the subgradient (<mathjax>$||g^{(t)}||_2$</mathjax>).  Next, we\n",
    "recursively apply the previous finding across all <mathjax>$t$</mathjax> to bound the sum of\n",
    "errors by the <em>initial</em> distance to <mathjax>$x^{*}$</mathjax> and the sum of all subgradient\n",
    "norms.  Then, we lower bound the sum of all errors with a minimum over <mathjax>$t$</mathjax>,\n",
    "giving us an upper bound on our error at iteration <mathjax>$t+1$</mathjax>. Finally, we use\n",
    "Assumption 4. to make that bound go to zero.</p>\n",
    "<p><strong>Step 1</strong> Upper bound <mathjax>$||x^{(t+1)} - x^{*}||$</mathjax>. Let <mathjax>$x^{*}$</mathjax> be any point in\n",
    "<mathjax>$\\arg\\min_{x} f(x)$</mathjax>. Then,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  ||x^{(t+1)} - x^{*}||_2^2\n",
    "  = & ||x^{(t)} - \\alpha^{(t)} g^{(t)} - x^{*}||_2^2\n",
    "    &&; \\text{# Definition of $x^{(t+1)}$} \\\\\n",
    "  = & ||x^{(t)} - x^{*}||_2^2 - 2 \\alpha^{(t)} \\langle g^{(t)}, x^{(t)} - x^{*} \\rangle + ( \\alpha^{(t)} )^2 ||g^{(t)}||_2^2\n",
    "    \\\\\n",
    "  \\le & ||x^{(t)} - x^{*}||_2^2 - 2 \\alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \\alpha^{(t)} )^2 ||g^{(t)}||_2^2\n",
    "    \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Our last step uses <mathjax>$f(x^{*}) \\ge f(x^{(t)}) + \\langle g^{(t)}, x^{*} - x^{(t)} \\rangle$</mathjax></p>\n",
    "<p><strong>Step 2</strong> Upper bound <mathjax>$||x^{(t+1)} - x^{*}||$</mathjax> by <mathjax>$||x^{(0)} - x^{*}||$</mathjax>.\n",
    "First, we apply Step 1 recursively to bound the current distance to <mathjax>$x^{*}$</mathjax></p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  ||x^{(t+1)} - x^{*}||_2^2\n",
    "  \\le & ||x^{(t)} - x^{*}||_2^2 - 2 \\alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \\alpha^{(t)} )^2 ||g^{(t)}||_2^2\n",
    "    \\\\\n",
    "  \\le & \\left( ||x^{(t-1)} - x^{*}||_2^2 - 2 \\alpha^{(t-1)} ( f(x^{(t-1)}) - f(x^{*}) ) + ( \\alpha^{(t-1)} )^2 ||g^{(t-1)}||_2^2 \\right) \\\\\n",
    "      & \\quad - 2 \\alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \\alpha^{(t)} )^2 ||g^{(t)}||_2^2\n",
    "      && \\text{# Apply recursion}\\\\\n",
    "    = & ||x^{(t-1)} - x^{*}||_2^2\n",
    "        - 2 \\sum_{\\tau=t-1}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) )\n",
    "        + \\sum_{\\tau=t-1}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2 \\\\\n",
    "  \\vdots \\\\\n",
    "  \\le & ||x^{(0)} - x^{*}||_2^2\n",
    "        - 2 \\sum_{\\tau=0}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) )\n",
    "        + \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Then we drop <mathjax>$||x^{(t+1)} - x^{*}||_2^2$</mathjax> from the left side it's lower bounded by zero,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  0\n",
    "  \\le & ||x^{(0)} - x^{*}||_2^2\n",
    "        - 2 \\sum_{\\tau=0}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) )\n",
    "        + \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2 \\\\\n",
    "  2 \\sum_{\\tau=0}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) )\n",
    "  \\le & ||x^{(0)} - x^{*}||_2^2\n",
    "        + \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p><strong>Step 3</strong> Upper bound current error. First, notice that we can lower bound the\n",
    "contents of the sum on the left with the minimum across <mathjax>$\\tau$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  \\sum_{\\tau=0}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) )\n",
    "  \\ge & \\left( \\min_{\\tau \\in 0 \\ldots t} f(x^{(\\tau)}) - f(x^{*}) \\right) \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Then divide by <mathjax>$2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )$</mathjax>,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  2 \\left( \\min_{\\tau \\in 0 \\ldots t} f(x^{(\\tau)}) - f(x^{*}) \\right) \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )\n",
    "  \\le & 2 \\sum_{\\tau=0}^{t} \\alpha^{(\\tau)} ( f(x^{(\\tau)}) - f(x^{*}) ) \\\\\n",
    "  \\le &; ||x^{(0)} - x^{*}||_2^2\n",
    "          + \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2 \\\\\n",
    "  \\left( \\min_{\\tau \\in 0 \\ldots t} f(x^{(\\tau)}) \\right) - f(x^{*})\n",
    "  \\le & \\frac{\n",
    "          ||x^{(0)} - x^{*}||_2^2\n",
    "          + \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2 ||g^{(\\tau)}||_2^2\n",
    "        }{\n",
    "          2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )\n",
    "        } \\\\\n",
    "  \\left( \\min_{\\tau \\in 0 \\ldots t} f(x^{(\\tau)}) \\right) - f(x^{*})\n",
    "  \\le & \\frac{\n",
    "          R^2\n",
    "          + G^2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2\n",
    "        }{\n",
    "          2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )\n",
    "        } \\\\\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p><strong>Step 4</strong> Making the bound go to zero.  Let <mathjax>$\\alpha^{(\\tau)} = \\frac{R}{G\n",
    "\\sqrt{t}}$</mathjax> (this is the minimizer of the right hand side for constant\n",
    "<mathjax>$\\alpha^{(\\tau)}$</mathjax>). Then,</p>\n",
    "<p><mathjax>$$\n",
    "\\begin{align*}\n",
    "  \\left( \\min_{\\tau \\in 0 \\ldots t} f(x^{(\\tau)}) \\right) - f(x^{*})\n",
    "  \\le & \\frac{\n",
    "          R^2 + G^2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )^2\n",
    "        }{\n",
    "          2 \\sum_{\\tau=0}^{t} ( \\alpha^{(\\tau)} )\n",
    "        } \\\\\n",
    "    = & \\frac{\n",
    "          R^2 + G^2 \\frac{R^2}{G^2} \\sum_{\\tau=0}^{t} \\frac{1}{t+1}\n",
    "        }{\n",
    "          2 \\frac{R}{G} \\sum_{\\tau=0}^{t} \\frac{1}{\\sqrt{t+1}}\n",
    "        } \\\\\n",
    "    = & \\frac{ RG }{ 2 \\sqrt{t+1} }\n",
    "        + \\frac{ RG } { 2 \\sqrt{t+1} }\n",
    "    = \\frac{ RG }{ \\sqrt{t+1} }\n",
    "\\end{align*}\n",
    "$$</mathjax></p>\n",
    "<p>Thus, we can conclude that if we want <mathjax>$f(x^{(t)}) - f(x^{*}) \\le \\epsilon$</mathjax>,\n",
    "we need <mathjax>$O(\\frac{1}{\\epsilon^2})$</mathjax> iterations. Compared to Gradient\n",
    "Descent's <mathjax>$O(\\frac{1}{\\epsilon})$</mathjax> convergence rate, Subgradient Descent looks\n",
    "pretty bad!</p>\n",
    "<h1><a name=\"usage\" href=\"#usage\">When should I use it?</a></h1>\n",
    "<p>As the implementation of Gradient Descent and Subgradient Descent are\n",
    "essentially the same, ease of use is always the first reason to use Subgradient\n",
    "Descent. Similarly, Subgradient Descent requires a minimal memory footprint,\n",
    "and has thus found a large following in the large scale machine learning\n",
    "community.</p>\n",
    "<p>As far as black box, first-order for non-differentiable convex problems go,\n",
    "it can be shown that Subgradient Descent is as (asymptotically) fast as we can\n",
    "hope for. That doesn't mean Subgradient Descent is as fast as you can get for\n",
    "your specific problem. Proximal Gradient methods, for example, are one such\n",
    "family of algorithms that allow you to exploit the properties of differentiable\n",
    "problems even if your problem isn't.</p>\n",
    "<h1><a name=\"extensions\" href=\"#extensions\">Extensions</a></h1>\n",
    "<p><strong>Step Size</strong> As stated previously, a common choice of step size is\n",
    "<mathjax>$\\alpha^{(t)} = \\frac{1}{t}$</mathjax>, but that's far from your only choice. Indeed, any\n",
    "step rule that satisfies the following conditions works when inserted into the\n",
    "above proof,</p>\n",
    "<p><mathjax>$$\n",
    "  \\sum_{t=0}^{\\infty} \\alpha^{(t)} = \\infty \\qquad\n",
    "  \\sum_{t=0}^{\\infty} ( \\alpha^{(t)} )^2 \\lt \\infty\n",
    "$$</mathjax></p>\n",
    "<p>For example, <mathjax>$\\alpha^{(t)} = \\frac{a}{b + t^{c}}$</mathjax> for positive constants <mathjax>$a$</mathjax>\n",
    "and <mathjax>$b$</mathjax> and <mathjax>$c \\in (0.5, 1]$</mathjax> also works. These conditions are referred to as\n",
    "being square-summable but not summable.</p>\n",
    "<p>If <mathjax>$f(x^{*})$</mathjax> is known ahead of time, another choice is <a href=\"http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf\">Polyak's Step\n",
    "Size</a>,</p>\n",
    "<p><mathjax>$$\n",
    "\\alpha^{(t)} = \\frac{ f(x^{(t)}) - f(x^{*}) }\n",
    "                    { ||g^{(t)}||_2^2 }\n",
    "$$</mathjax></p>\n",
    "<p>If <mathjax>$f(x^{*})$</mathjax> isn't know, then <mathjax>$\\alpha^{(t)} = \\frac{ f(x^{(t)}) -\n",
    "f^{(t)}_{best} + \\gamma^{(t)} }{ ||g^{(t)}||_2^2 }$</mathjax> is also valid for\n",
    "<mathjax>$f^{(t)}_{best} = \\min_{\\tau \\in 0\\ldots t} f(x^{(t)})$</mathjax> and <mathjax>$\\gamma^{(t)}$</mathjax>\n",
    "being square-summable and not summable.</p>\n",
    "<p><strong>Checking Convergence</strong> In short, there are no easy ways to know when to stop\n",
    "with Subgradient Descent. Checking if <mathjax>$\\nabla f(x)$</mathjax> is small doesn't make sense\n",
    "because <mathjax>$\\nabla f(x)$</mathjax> isn't defined at some points and <mathjax>$g_x$</mathjax> doesn't\n",
    "necessarily get small near <mathjax>$x \\triangleq x^{*}$</mathjax>. Instead, a fixed number of\n",
    "iterations is typically used.</p>\n",
    "<h1><a name=\"references\" href=\"#references\">References</a></h1>\n",
    "<p><strong>Proof of Convergence</strong> The proof of convergence for Subgradient Descent is\n",
    "taken nearly verbatim from Stephen Boyd's <a href=\"http://www.stanford.edu/class/ee392o/subgrad_method.pdf\">lecture notes for\n",
    "EE392o</a> course in 2003.</p>\n",
    "<p><strong>Polyak Step Size</strong> The algorithm for the Polyak step size was taken from\n",
    "page 23 of Stephen Boyd's <a href=\"http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf\">lecture slides for EE364b</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "def subgradient_descent(function, subgradient, x0, alpha, n_iterations=100):\n",
    "\n",
    "    xs = [x0]\n",
    "    x_best = x0\n",
    "    for t in range(n_iterations):\n",
    "        x = xs[-1]\n",
    "        g = subgradient(x)\n",
    "        x_plus = x - alpha(t, function(x), function(x_best), g) * g\n",
    "        xs.append(x_plus)\n",
    "        if function(x_plus) < function(x_best):\n",
    "            x_best = x_plus\n",
    "    return xs\n",
    "\n",
    "\n",
    "def polyak(t, f_x, f_x_best, g):\n",
    "    if abs(g) > 0:\n",
    "        return (f_x - f_x_best + 1.0 / (t + 1)) / (g * g)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ### SUBGRADIENT DESCENT ###\n",
    "\n",
    "    function = np.abs\n",
    "    subgradient = np.sign\n",
    "    x0 = 0.75\n",
    "    n_iterations = 10\n",
    "\n",
    "    iterates = subgradient_descent(\n",
    "        function, subgradient, x0, polyak, n_iterations=n_iterations)\n",
    "    iterates = np.asarray(iterates)\n",
    "\n",
    "    ### PLOTTING ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
